{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>areaDesc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - Essex County</td>\n",
       "      <td>42.0409</td>\n",
       "      <td>-83.1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - Essex County</td>\n",
       "      <td>42.0737</td>\n",
       "      <td>-83.1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - Essex County</td>\n",
       "      <td>42.0902</td>\n",
       "      <td>-83.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - Essex County</td>\n",
       "      <td>42.0903</td>\n",
       "      <td>-83.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - Essex County</td>\n",
       "      <td>42.1025</td>\n",
       "      <td>-83.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - comté d'Essex</td>\n",
       "      <td>41.8127</td>\n",
       "      <td>-82.5705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - comté d'Essex</td>\n",
       "      <td>41.7225</td>\n",
       "      <td>-82.6052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - comté d'Essex</td>\n",
       "      <td>41.7134</td>\n",
       "      <td>-82.6941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - comté d'Essex</td>\n",
       "      <td>41.9268</td>\n",
       "      <td>-82.8988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>Windsor - Leamington - comté d'Essex</td>\n",
       "      <td>42.0409</td>\n",
       "      <td>-83.1223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            event                              areaDesc  latitude  longitude\n",
       "0    thunderstorm   Windsor - Leamington - Essex County   42.0409   -83.1223\n",
       "1    thunderstorm   Windsor - Leamington - Essex County   42.0737   -83.1387\n",
       "2    thunderstorm   Windsor - Leamington - Essex County   42.0902   -83.1333\n",
       "3    thunderstorm   Windsor - Leamington - Essex County   42.0903   -83.1333\n",
       "4    thunderstorm   Windsor - Leamington - Essex County   42.1025   -83.1293\n",
       "..            ...                                   ...       ...        ...\n",
       "339  thunderstorm  Windsor - Leamington - comté d'Essex   41.8127   -82.5705\n",
       "340  thunderstorm  Windsor - Leamington - comté d'Essex   41.7225   -82.6052\n",
       "341  thunderstorm  Windsor - Leamington - comté d'Essex   41.7134   -82.6941\n",
       "342  thunderstorm  Windsor - Leamington - comté d'Essex   41.9268   -82.8988\n",
       "343  thunderstorm  Windsor - Leamington - comté d'Essex   42.0409   -83.1223\n",
       "\n",
       "[344 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "# Parse the XML file\n",
    "mytree = et.parse(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\Weather\\T_ONCN00_C_LAND_202308120336_3605043431.cap\")\n",
    "root = mytree.getroot()\n",
    "\n",
    "# Namespace dictionary\n",
    "namespaces = {'cap': 'urn:oasis:names:tc:emergency:cap:1.2'}\n",
    "\n",
    "# Extract event data\n",
    "event = root.find('.//cap:event', namespaces).text\n",
    "\n",
    "# Extract polygon data into a list of dictionaries\n",
    "data = []\n",
    "for area in root.findall('.//cap:area', namespaces):\n",
    "    area_desc = area.find('.//cap:areaDesc', namespaces).text\n",
    "    polygon_coords = area.find('.//cap:polygon', namespaces).text\n",
    "    coords = polygon_coords.split()  # Split coordinates into individual pairs\n",
    "    \n",
    "    # Create a dictionary for each set of coordinates\n",
    "    for coord_pair in coords:\n",
    "        lat, lon = map(float, coord_pair.split(','))\n",
    "        data.append({'event': event, 'areaDesc': area_desc, 'latitude': lat, 'longitude': lon})\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "polygon_df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "polygon_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province</th>\n",
       "      <th>region</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>825620</th>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Greater Vancouver</td>\n",
       "      <td>V4A5A3</td>\n",
       "      <td>49.038728</td>\n",
       "      <td>-122.785046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251769</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Centre-du-Québec</td>\n",
       "      <td>J2E1M4</td>\n",
       "      <td>45.895928</td>\n",
       "      <td>-72.519031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252689</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Estrie</td>\n",
       "      <td>J2G5W1</td>\n",
       "      <td>45.411944</td>\n",
       "      <td>-72.733143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198766</th>\n",
       "      <td>Quebec</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>H2L4B4</td>\n",
       "      <td>45.539956</td>\n",
       "      <td>-73.615088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434973</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Peel</td>\n",
       "      <td>L4W3T9</td>\n",
       "      <td>43.620498</td>\n",
       "      <td>-79.618616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745994</th>\n",
       "      <td>Alberta</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>T6B0X3</td>\n",
       "      <td>53.530288</td>\n",
       "      <td>-113.431717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30144</th>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>B3L3G7</td>\n",
       "      <td>44.643559</td>\n",
       "      <td>-63.612203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615827</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>Greater Sudbury</td>\n",
       "      <td>P3E1E3</td>\n",
       "      <td>46.489240</td>\n",
       "      <td>-80.990750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880136</th>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Capital</td>\n",
       "      <td>V8Z4M9</td>\n",
       "      <td>48.458248</td>\n",
       "      <td>-123.409867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86488</th>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>E5C2P3</td>\n",
       "      <td>45.117226</td>\n",
       "      <td>-66.847864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                province             region zipcode   latitude   longitude\n",
       "825620  British Columbia  Greater Vancouver  V4A5A3  49.038728 -122.785046\n",
       "251769            Quebec   Centre-du-Québec  J2E1M4  45.895928  -72.519031\n",
       "252689            Quebec             Estrie  J2G5W1  45.411944  -72.733143\n",
       "198766            Quebec           Montréal  H2L4B4  45.539956  -73.615088\n",
       "434973           Ontario               Peel  L4W3T9  43.620498  -79.618616\n",
       "745994           Alberta           Edmonton  T6B0X3  53.530288 -113.431717\n",
       "30144        Nova Scotia            Halifax  B3L3G7  44.643559  -63.612203\n",
       "615827           Ontario    Greater Sudbury  P3E1E3  46.489240  -80.990750\n",
       "880136  British Columbia            Capital  V8Z4M9  48.458248 -123.409867\n",
       "86488      New Brunswick          Charlotte  E5C2P3  45.117226  -66.847864"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cities = pd.read_csv(r'C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\ca_geo_dimension.csv')\n",
    "cities.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [event]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "# Polygon coordinates\n",
    "polygon_coords = polygon_df[['longitude','latitude']]\n",
    "\n",
    "# Create a Shapely Polygon\n",
    "polygon = Polygon(polygon_coords)\n",
    "\n",
    "# List to store filtered city data\n",
    "filtered_cities = []\n",
    "\n",
    "# Iterate through each city\n",
    "for index, city in cities.iterrows():\n",
    "    city_point = Point(city['longitude'], city['latitude'])\n",
    "    \n",
    "    # Check if the city is inside the polygon\n",
    "    if city_point.within(polygon):\n",
    "        filtered_cities.append({'province': city['province'], 'region': city['region']})\n",
    "\n",
    "# Create a DataFrame from the filtered cities\n",
    "filtered_cities_df = pd.DataFrame(filtered_cities)\n",
    "\n",
    "# Add 'event' column to the filtered cities DataFrame\n",
    "event_name = \"thunderstorm\"  # Replace with the actual event name\n",
    "filtered_cities_df['event'] = event_name\n",
    "\n",
    "filtered_cities_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       province        region         event\n",
      "545613  Ontario         Essex  thunderstorm\n",
      "545619  Ontario  Chatham-Kent  thunderstorm\n",
      "545621  Ontario         Essex  thunderstorm\n",
      "545626  Ontario         Essex  thunderstorm\n",
      "545650  Ontario         Essex  thunderstorm\n",
      "...         ...           ...           ...\n",
      "608501  Ontario         Essex  thunderstorm\n",
      "608502  Ontario         Essex  thunderstorm\n",
      "608503  Ontario         Essex  thunderstorm\n",
      "608504  Ontario         Essex  thunderstorm\n",
      "608505  Ontario         Essex  thunderstorm\n",
      "\n",
      "[11180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "# Parse the XML file\n",
    "mytree = et.parse(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\Weather\\T_ONCN00_C_LAND_202308120336_3605043431.cap\")\n",
    "root = mytree.getroot()\n",
    "\n",
    "# Namespace dictionary\n",
    "namespaces = {'cap': 'urn:oasis:names:tc:emergency:cap:1.2'}\n",
    "\n",
    "# Extract event data\n",
    "event = root.find('.//cap:event', namespaces).text\n",
    "\n",
    "# Extract polygon coordinates\n",
    "polygon_coords = root.find('.//cap:area/cap:polygon', namespaces).text\n",
    "polygon_points = [tuple(map(float, point.split(','))) for point in polygon_coords.split()]\n",
    "\n",
    "\n",
    "cities_df = pd.read_csv(r'C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\ca_geo_dimension.csv')\n",
    "\n",
    "# Check if each city is inside the polygon\n",
    "inside_polygon = []\n",
    "for index, city in cities_df.iterrows():\n",
    "    lat, lon = city['latitude'], city['longitude']\n",
    "    point = (lat, lon)\n",
    "    \n",
    "    # Check if the point is inside the polygon\n",
    "    inside = False\n",
    "    i, j = 0, len(polygon_points) - 1\n",
    "    while i < len(polygon_points):\n",
    "        if ((polygon_points[i][1] > point[1]) != (polygon_points[j][1] > point[1])) and \\\n",
    "                (point[0] < (polygon_points[j][0] - polygon_points[i][0]) * (point[1] - polygon_points[i][1]) / \n",
    "                             (polygon_points[j][1] - polygon_points[i][1]) + polygon_points[i][0]):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "        i += 1\n",
    "    \n",
    "    inside_polygon.append(inside)\n",
    "\n",
    "# Create a new DataFrame with cities inside the polygon\n",
    "cities_inside_polygon_df = cities_df[inside_polygon][['province', 'region']].copy()\n",
    "cities_inside_polygon_df['event'] = event\n",
    "\n",
    "# Print the DataFrame with cities inside the polygon\n",
    "print(cities_inside_polygon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [province, region, zipcode, event]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Parse the XML file\n",
    "mytree = et.parse(r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\Weather\\T_ONCN00_C_LAND_202308120336_2772920413.cap\")\n",
    "root = mytree.getroot()\n",
    "\n",
    "# Namespace dictionary\n",
    "namespaces = {'cap': 'urn:oasis:names:tc:emergency:cap:1.2'}\n",
    "\n",
    "# Extract event data\n",
    "event = root.find('.//cap:event', namespaces).text\n",
    "\n",
    "# Extract polygon coordinates\n",
    "polygon_coords = root.find('.//cap:area/cap:polygon', namespaces).text\n",
    "polygon_points = [tuple(map(float, point.split(','))) for point in polygon_coords.split()]\n",
    "\n",
    "# Create a Shapely Polygon from the polygon points\n",
    "polygon = Polygon(polygon_points)\n",
    "\n",
    "cities_df = pd.read_csv(r'C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\ca_geo_dimension.csv')\n",
    "\n",
    "# Check if each city is inside the polygon using Shapely's contains method\n",
    "inside_polygon = []\n",
    "for index, city in cities_df.iterrows():\n",
    "    lat, lon = city['latitude'], city['longitude']\n",
    "    point = Point(lon, lat)  # Shapely uses (x, y) order\n",
    "    \n",
    "    inside = polygon.contains(point)\n",
    "    inside_polygon.append(inside)\n",
    "\n",
    "# Create a new DataFrame with cities inside the polygon\n",
    "cities_inside_polygon_df = cities_df[inside_polygon][['province', 'region', 'zipcode']].copy()\n",
    "cities_inside_polygon_df['event'] = event\n",
    "\n",
    "# Print the DataFrame with cities inside the polygon\n",
    "print(cities_inside_polygon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [province, region, event]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [province, region, event]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Folder path containing the CAP files\n",
    "folder_path = r\"C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\Weather\"\n",
    "\n",
    "# Namespace dictionary\n",
    "namespaces = {'cap': 'urn:oasis:names:tc:emergency:cap:1.2'}\n",
    "\n",
    "# Get a list of all CAP files in the folder\n",
    "file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(\".cap\")]\n",
    "\n",
    "# Iterate over each file\n",
    "for file_path in file_paths:\n",
    "    # Parse the XML file\n",
    "    mytree = et.parse(file_path)\n",
    "    root = mytree.getroot()\n",
    "\n",
    "    # Extract event data\n",
    "    event = root.find('.//cap:event', namespaces).text\n",
    "\n",
    "    # Extract polygon coordinates\n",
    "    polygon_coords = root.find('.//cap:area/cap:polygon', namespaces).text\n",
    "    polygon_points = [tuple(map(float, point.split(','))) for point in polygon_coords.split()]\n",
    "\n",
    "    cities_df = pd.read_csv(r'C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\ca_geo_dimension.csv')\n",
    "\n",
    "    # Create a Shapely Polygon from the polygon points\n",
    "    polygon = Polygon(polygon_points)\n",
    "\n",
    "    # Check if each city is inside the polygon using Shapely's contains method\n",
    "    inside_polygon = []\n",
    "    for index, city in cities_df.iterrows():\n",
    "        lat, lon = city['latitude'], city['longitude']\n",
    "        point = Point(lon, lat)  # Shapely uses (x, y) order\n",
    "\n",
    "        inside = polygon.contains(point)\n",
    "        inside_polygon.append(inside)\n",
    "\n",
    "    # Create a new DataFrame with cities inside the polygon\n",
    "    cities_inside_polygon_df = cities_df[inside_polygon][['province', 'region']].copy()\n",
    "    cities_inside_polygon_df['event'] = event\n",
    "\n",
    "    # Print the DataFrame with cities inside the polygon\n",
    "    print(cities_inside_polygon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "from shapely.geometry import Point, Polygon\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Base URL for CAP files\n",
    "base_url = \"https://dd.weather.gc.ca/alerts/cap/\"\n",
    "\n",
    "# Get current date in YYYYMMDD format\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Create a list of two-digit hour strings\n",
    "hours = []\n",
    "for i in range(0, 24):\n",
    "    hours.append(f'{i:02}')\n",
    "codes =['CWUL','CWEG','CWNT','CWWG','CWVR','CWTO','CYQX','CWAO','CWIS','CWHX','LAND']\n",
    "# Create URLs for each hour\n",
    "urls = []\n",
    "for code in codes:\n",
    "    for hour in hours:\n",
    "        url = base_url + current_date + '/' + code + '/'+ hour + '/'\n",
    "        urls.append(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the URL for the CAP files\n",
    "\n",
    "# Make a request to the URL to get the list of CAP files\n",
    "response = requests.get(url)\n",
    "cap_links = response.text.split(\"\\n\")\n",
    "\n",
    "# Filter CAP links to get only the ones you're interested in\n",
    "cap_links = [link for link in cap_links if link.endswith(\".cap\")]\n",
    "cap_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWUL/22/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWNT/22/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/22/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/21/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/LAND/22/ to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/LAND/21/ to the list.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "from shapely.geometry import Point, Polygon\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Base URL for CAP files\n",
    "base_url = \"https://dd.weather.gc.ca/alerts/cap/\"\n",
    "\n",
    "\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Create a list of two-digit hour strings\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "hours = []\n",
    "for i in range(3):\n",
    "    hours.append(f'{(now - datetime.timedelta(hours=i)).hour:02}')\n",
    "\n",
    "codes = ['CWUL', 'CWEG', 'CWNT', 'CWWG', 'CWVR', 'CWTO', 'CYQX', 'CWAO', 'CWIS', 'CWHX', 'LAND']\n",
    "\n",
    "# Create URLs for each hour and code\n",
    "urls = []\n",
    "for code in codes:\n",
    "    for hour in hours:\n",
    "        url = base_url + current_date + '/' + code + '/' + hour + '/'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:  # Check if response is successful\n",
    "            urls.append(url)\n",
    "            print(f\"Added {url} to the list.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store URLs with .cap files\n",
    "url_cap = []\n",
    "\n",
    "import time\n",
    " for url in urls:\n",
    "   file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path) if filename.endswith(\".cap\")]\n",
    "\n",
    "for code in codes:\n",
    "    for hour in hours:\n",
    "        url = base_url + current_date + '/' + code + '/' + hour + '/'\n",
    "        response = requests.get(url, timeout=10)  # Adjust the timeout value as needed\n",
    "        if response.status_code == 200 and response.url.endswith('.cap'):\n",
    "            url_cap.append(response.url)\n",
    "            print(f\"Added {response.url} to the list of .cap files.\")\n",
    "        time.sleep(1)  # Add a 1-second delay between requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, timeout=10)  # Adjust the timeout value as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store URLs with .cap files\n",
    "url_cap = []\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "for code in codes:\n",
    "    for hour in hours:\n",
    "        url = base_url + current_date + '/' + code + '/' + hour + '/'\n",
    "        response = requests.get(url, timeout=10)  # Adjust the timeout value as needed\n",
    "        if response.status_code == 200 and response.url.endswith('.cap'):\n",
    "            url_cap.append(response.url)\n",
    "            print(f\"Added {response.url} to the list of .cap files.\")\n",
    "        time.sleep(1)  # Add a 1-second delay between requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over the CAP links and download the files\n",
    "for cap_link in cap_links:\n",
    "    cap_url = url + \"/\" + cap_link\n",
    "    file_path = os.path.join(download_folder, cap_link)\n",
    "    \n",
    "    # Download the CAP file\n",
    "    cap_response = requests.get(cap_url)\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(cap_response.content)\n",
    "    \n",
    "    # Process the downloaded CAP file\n",
    "    # Parse the XML file\n",
    "    mytree = et.fromstring(cap_response.content)\n",
    "    namespaces = {'cap': 'urn:oasis:names:tc:emergency:cap:1.2'}\n",
    "\n",
    "    # Extract event data\n",
    "    event = mytree.find('.//cap:event', namespaces).text\n",
    "\n",
    "    # Extract polygon coordinates\n",
    "    polygon_coords = mytree.find('.//cap:area/cap:polygon', namespaces).text\n",
    "    polygon_points = [tuple(map(float, point.split(','))) for point in polygon_coords.split()]\n",
    "\n",
    "    cities_df = pd.read_csv(r'C:\\Users\\srika\\OneDrive\\Documents\\York\\Sem-1 york\\MMAI 5100 - database fundamentals\\ca_geo_dimension.csv')\n",
    "\n",
    "    # Create a Shapely Polygon from the polygon points\n",
    "    polygon = Polygon(polygon_points)\n",
    "\n",
    "    # Check if each city is inside the polygon using Shapely's contains method\n",
    "    inside_polygon = []\n",
    "    for index, city in cities_df.iterrows():\n",
    "        lat, lon = city['latitude'], city['longitude']\n",
    "        point = Point(lon, lat)  # Shapely uses (x, y) order\n",
    "\n",
    "        inside = polygon.contains(point)\n",
    "        inside_polygon.append(inside)\n",
    "\n",
    "    # Create a new DataFrame with cities inside the polygon\n",
    "    cities_inside_polygon_df = cities_df[inside_polygon][['province', 'region']].copy()\n",
    "    cities_inside_polygon_df['event'] = event\n",
    "\n",
    "    # Print the DataFrame with cities inside the polygon\n",
    "    print(cities_inside_polygon_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WOCN21_C_CWVR_202308122327_1137547568.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WWCN11_C_CWVR_202308122328_1348165370.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WWCN11_C_CWVR_202308122330_3343082376.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122348_0562913125.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122348_2787214325.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_0463152595.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_2378960251.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_3648543961.cap to the list.\n",
      "Added https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WZCN80_C_CWTO_202308122316_2360015276.cap to the list.\n",
      "List of URLs with .cap files:\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WOCN21_C_CWVR_202308122327_1137547568.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WWCN11_C_CWVR_202308122328_1348165370.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWVR/23/T_WWCN11_C_CWVR_202308122330_3343082376.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122348_0562913125.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122348_2787214325.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_0463152595.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_2378960251.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WHCN13_C_CWTO_202308122356_3648543961.cap\n",
      "https://dd.weather.gc.ca/alerts/cap/20230812/CWTO/23/T_WZCN80_C_CWTO_202308122316_2360015276.cap\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Base URL for CAP files\n",
    "base_url = \"https://dd.weather.gc.ca/alerts/cap/\"\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# Create a list of two-digit hour strings for the past 3 hours\n",
    "now = datetime.now()\n",
    "hours = [(now - timedelta(hours=i)).strftime('%H') for i in range(1)]\n",
    "\n",
    "# List of responsible office codes\n",
    "responsible_offices = ['CWUL', 'CWEG', 'CWNT', 'CWWG', 'CWVR', 'CWTO', 'CYQX', 'CWAO', 'CWIS', 'CWHX', 'LAND']\n",
    "\n",
    "# Create a list to store URLs ending with .cap\n",
    "urls_cap = []\n",
    "\n",
    "# Create URLs for each responsible office, hour, and code\n",
    "for office in responsible_offices:\n",
    "    for hour in hours:\n",
    "        url = f\"{base_url}{current_date}/{office}/{hour}/\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                # Extract filenames from the response using regular expressions\n",
    "                filenames = re.findall(r'href=\"(.*\\.cap)\"', response.text)\n",
    "                # Create complete URLs for .cap files and add them to the list\n",
    "                for filename in filenames:\n",
    "                    cap_url = url + filename\n",
    "                    urls_cap.append(cap_url)\n",
    "                    print(f\"Added {cap_url} to the list.\")\n",
    "        except requests.Timeout:\n",
    "            print(f\"Request to {url} timed out.\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Request to {url} failed: {e}\")\n",
    "\n",
    "# Print the collected URLs\n",
    "print(\"List of URLs with .cap files:\")\n",
    "for url in urls_cap:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
